import os
from pinecone import Pinecone, ServerlessSpec
from typing import List, Dict, Any, Optional
from app.models import VectorSearchResult
import logging
import json
import pickle
from pathlib import Path
import numpy as np
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

logger = logging.getLogger(__name__)

class PineconeService:
    def __init__(self):
        self.pc = None  # Pinecone client
        self.index = None
        self.index_name = os.getenv("PINECONE_INDEX_NAME", "rag-system-index")
        self.local_storage_path = Path("./local_vector_storage")
        self.local_storage_path.mkdir(exist_ok=True)
        
    def _get_local_storage_file(self, device_id: str) -> Path:
        """Get local storage file path for a device"""
        return self.local_storage_path / f"device_{device_id}_vectors.json"
        
    def _load_local_vectors(self, device_id: str) -> List[Dict[str, Any]]:
        """Load vectors from local storage"""
        storage_file = self._get_local_storage_file(device_id)
        if storage_file.exists():
            try:
                with open(storage_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"Failed to load local vectors: {e}")
        return []
        
    def _save_local_vectors(self, device_id: str, vectors: List[Dict[str, Any]]) -> bool:
        """Save vectors to local storage"""
        try:
            storage_file = self._get_local_storage_file(device_id)
            with open(storage_file, 'w', encoding='utf-8') as f:
                json.dump(vectors, f, indent=2)
            return True
        except Exception as e:
            logger.error(f"Failed to save local vectors: {e}")
            return False
            
    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """Calculate cosine similarity between two vectors"""
        try:
            a_np = np.array(a)
            b_np = np.array(b)
            return float(np.dot(a_np, b_np) / (np.linalg.norm(a_np) * np.linalg.norm(b_np)))
        except:
            return 0.0
        
    async def initialize_pinecone(self):
        """Initialize Pinecone connection"""
        try:
            api_key = os.getenv("PINECONE_API_KEY")
            
            if not api_key or api_key == "dummy_key_for_testing":
                logger.warning("‚ùå Pinecone API key not provided or is dummy key")
                logger.info("üìù Pinecone service will be disabled (using local storage for vectors)")
                return
            
            # Initialize Pinecone with the new API
            self.pc = Pinecone(api_key=api_key)
            
            # Check if index exists first
            existing_indexes = [index.name for index in self.pc.list_indexes()]
            
            if self.index_name not in existing_indexes:
                logger.warning(f"‚ùå Pinecone index '{self.index_name}' does not exist")
                logger.info("üìù Please create the index manually or check your pod limits")
                logger.info("üìù Pinecone service will be disabled (using local storage for vectors)")
                return
            
            # Try to connect to existing index
            self.index = self.pc.Index(self.index_name)
            
            # Test the connection with a simple describe operation
            stats = self.index.describe_index_stats()
            print("‚úÖ Pinecone connected successfully")
            logger.info("‚úÖ Pinecone initialized successfully")
            
        except Exception as e:
            error_msg = str(e)
            if "max pods allowed" in error_msg.lower() or "pod" in error_msg.lower():
                logger.warning("‚ùå Pinecone pod limit reached")
                logger.info("üìù Please check your Pinecone console to manage pod limits")
                logger.info("üìù Pinecone service will be disabled (using local storage for vectors)")
            elif "index not found" in error_msg.lower():
                logger.warning("‚ùå Pinecone index not found")
                logger.info("üìù Please create the index manually in your Pinecone console")
                logger.info("üìù Pinecone service will be disabled (using local storage for vectors)")
            else:
                logger.error(f"‚ùå Failed to initialize Pinecone: {e}")
                logger.info("üìù Pinecone service will be disabled (using local storage for vectors)")
            
            # Set index to None to enable fallback mode
            self.index = None
    
    async def upsert_vectors(
        self, 
        vectors: List[Dict[str, Any]], 
        device_id: str
    ) -> bool:
        """Upsert vectors to Pinecone with device isolation or local storage fallback"""
        try:
            if self.index:
                # Use Pinecone if available
                # Add device_id to metadata for isolation
                for vector in vectors:
                    if 'metadata' not in vector:
                        vector['metadata'] = {}
                    vector['metadata']['device_id'] = device_id
                
                self.index.upsert(vectors=vectors, namespace=f"device_{device_id}")
                logger.info(f"‚úÖ Upserted {len(vectors)} vectors to Pinecone for device {device_id}")
                return True
            else:
                # Fallback to local storage
                existing_vectors = self._load_local_vectors(device_id)
                
                # Add new vectors (simple append for now - could be improved with deduplication)
                for vector in vectors:
                    if 'metadata' not in vector:
                        vector['metadata'] = {}
                    vector['metadata']['device_id'] = device_id
                    # Convert numpy arrays to lists for JSON serialization
                    if 'values' in vector and hasattr(vector['values'], 'tolist'):
                        vector['values'] = vector['values'].tolist()
                    existing_vectors.append(vector)
                
                if self._save_local_vectors(device_id, existing_vectors):
                    logger.info(f"‚úÖ Stored {len(vectors)} vectors locally for device {device_id}")
                    return True
                else:
                    logger.error(f"‚ùå Failed to store vectors locally for device {device_id}")
                    return False
            
        except Exception as e:
            logger.error(f"‚ùå Failed to upsert vectors: {e}")
            return False
    
    async def search_vectors(
        self, 
        query_vector: List[float], 
        device_id: str,
        top_k: int = 5,
        filter_metadata: Optional[Dict[str, Any]] = None
    ) -> List[VectorSearchResult]:
        """Search vectors with device isolation or local storage fallback"""
        try:
            if self.index:
                # Use Pinecone if available
                # Ensure device isolation in filter
                device_filter = {"device_id": device_id}
                if filter_metadata:
                    device_filter.update(filter_metadata)
                
                results = self.index.query(
                    vector=query_vector,
                    top_k=top_k,
                    include_metadata=True,
                    namespace=f"device_{device_id}",
                    filter=device_filter
                )
                
                search_results = []
                for match in results.matches:
                    search_results.append(VectorSearchResult(
                        content=match.metadata.get('content', ''),
                        metadata=match.metadata,
                        score=match.score
                    ))
                
                return search_results
            else:
                # Fallback to local storage with simple similarity search
                vectors = self._load_local_vectors(device_id)
                
                if not vectors:
                    return []
                
                # Calculate similarities
                similarities = []
                for i, vector in enumerate(vectors):
                    if 'values' in vector:
                        similarity = self._cosine_similarity(query_vector, vector['values'])
                        similarities.append((i, similarity, vector))
                
                # Sort by similarity and take top_k
                similarities.sort(key=lambda x: x[1], reverse=True)
                top_results = similarities[:top_k]
                
                search_results = []
                for _, score, vector in top_results:
                    metadata = vector.get('metadata', {})
                    
                    # Apply filter if provided
                    if filter_metadata:
                        skip = False
                        for key, value in filter_metadata.items():
                            if metadata.get(key) != value:
                                skip = True
                                break
                        if skip:
                            continue
                    
                    search_results.append(VectorSearchResult(
                        content=metadata.get('content', ''),
                        metadata=metadata,
                        score=score
                    ))
                
                logger.info(f"‚úÖ Found {len(search_results)} results from local storage for device {device_id}")
                return search_results
            
        except Exception as e:
            logger.error(f"‚ùå Failed to search vectors: {e}")
            return []
    
    async def delete_vectors(
        self, 
        vector_ids: List[str], 
        device_id: str
    ) -> bool:
        """Delete vectors by IDs with device isolation"""
        try:
            if self.index:
                # Use Pinecone if available
                self.index.delete(ids=vector_ids, namespace=f"device_{device_id}")
                logger.info(f"‚úÖ Deleted {len(vector_ids)} vectors from Pinecone for device {device_id}")
                return True
            else:
                # Fallback to local storage deletion
                vectors = self._load_local_vectors(device_id)
                
                if not vectors:
                    logger.info(f"üìù No vectors found in local storage for device {device_id}")
                    return True  # Consider success if no vectors exist
                
                # Filter out vectors with matching IDs
                initial_count = len(vectors)
                filtered_vectors = [
                    vector for vector in vectors 
                    if vector.get('id') not in vector_ids
                ]
                
                deleted_count = initial_count - len(filtered_vectors)
                
                if deleted_count > 0:
                    # Save the filtered vectors back to local storage
                    if self._save_local_vectors(device_id, filtered_vectors):
                        logger.info(f"‚úÖ Deleted {deleted_count} vectors from local storage for device {device_id}")
                        return True
                    else:
                        logger.error(f"‚ùå Failed to save filtered vectors to local storage for device {device_id}")
                        return False
                else:
                    logger.info(f"üìù No matching vectors found to delete for device {device_id}")
                    return True  # Consider success if no matching vectors found
            
        except Exception as e:
            logger.error(f"‚ùå Failed to delete vectors: {e}")
            return False
    
    async def delete_document_vectors(self, document_id: str, device_id: str) -> bool:
        """Delete all vectors for a specific document"""
        try:
            if self.index:
                # Use Pinecone metadata filtering to delete all vectors for this document
                self.index.delete(
                    filter={"document_id": document_id},
                    namespace=f"device_{device_id}"
                )
                logger.info(f"‚úÖ Deleted all vectors for document {document_id} from Pinecone for device {device_id}")
                return True
            else:
                # Fallback to local storage deletion
                vectors = self._load_local_vectors(device_id)
                
                if not vectors:
                    logger.info(f"üìù No vectors found in local storage for device {device_id}")
                    return True
                
                # Filter out vectors with matching document_id
                initial_count = len(vectors)
                filtered_vectors = [
                    vector for vector in vectors 
                    if vector.get('metadata', {}).get('document_id') != document_id
                ]
                
                deleted_count = initial_count - len(filtered_vectors)
                
                if deleted_count > 0:
                    # Save the filtered vectors back to local storage
                    if self._save_local_vectors(device_id, filtered_vectors):
                        logger.info(f"‚úÖ Deleted {deleted_count} vectors for document {document_id} from local storage for device {device_id}")
                        return True
                    else:
                        logger.error(f"‚ùå Failed to save filtered vectors to local storage for device {device_id}")
                        return False
                else:
                    logger.info(f"üìù No vectors found for document {document_id} in device {device_id}")
                    return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to delete document vectors: {e}")
            return False
    
    async def cleanup_orphaned_vectors(self, device_id: str, valid_document_ids: List[str]) -> int:
        """Remove vectors that don't correspond to existing documents"""
        try:
            if self.index:
                # For Pinecone, we'd need to query and filter, which is complex
                # This feature would require fetching all vectors and checking metadata
                logger.info("üîß Orphaned vector cleanup for Pinecone not implemented (requires manual intervention)")
                return 0
            else:
                # For local storage, we can easily clean up
                vectors = self._load_local_vectors(device_id)
                
                if not vectors:
                    return 0
                
                initial_count = len(vectors)
                
                # Keep only vectors that have document_ids in the valid list
                valid_vectors = [
                    vector for vector in vectors 
                    if vector.get('metadata', {}).get('document_id') in valid_document_ids
                ]
                
                orphaned_count = initial_count - len(valid_vectors)
                
                if orphaned_count > 0:
                    if self._save_local_vectors(device_id, valid_vectors):
                        logger.info(f"üßπ Cleaned up {orphaned_count} orphaned vectors for device {device_id}")
                        return orphaned_count
                    else:
                        logger.error(f"‚ùå Failed to save cleaned vectors for device {device_id}")
                        return 0
                else:
                    logger.info(f"‚úÖ No orphaned vectors found for device {device_id}")
                    return 0
            
        except Exception as e:
            logger.error(f"‚ùå Failed to cleanup orphaned vectors: {e}")
            return 0
    
    async def get_index_stats(self, device_id: str) -> Dict[str, Any]:
        """Get index statistics for a specific device"""
        try:
            if self.index:
                # Use Pinecone if available
                stats = self.index.describe_index_stats()
                device_namespace = f"device_{device_id}"
                
                if device_namespace in stats.namespaces:
                    return {
                        "total_vectors": stats.namespaces[device_namespace].vector_count,
                        "device_id": device_id,
                        "namespace": device_namespace,
                        "storage_type": "pinecone"
                    }
                else:
                    return {
                        "total_vectors": 0,
                        "device_id": device_id,
                        "namespace": device_namespace,
                        "storage_type": "pinecone"
                    }
            else:
                # Use local storage
                vectors = self._load_local_vectors(device_id)
                return {
                    "total_vectors": len(vectors),
                    "device_id": device_id,
                    "namespace": f"device_{device_id}",
                    "storage_type": "local"
                }
                
        except Exception as e:
            logger.error(f"‚ùå Failed to get index stats: {e}")
            return {
                "total_vectors": 0,
                "device_id": device_id,
                "error": str(e),
                "storage_type": "unknown"
            }

# Global instance
pinecone_service = PineconeService()
